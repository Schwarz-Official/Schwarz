{"ast":null,"code":"import { eat, finishToken, lookaheadTypeAndKeyword, match, nextTokenStart } from \"../tokenizer/index\";\nimport { formatTokenType, TokenType as tt } from \"../tokenizer/types\";\nimport { charCodes } from \"../util/charcodes\";\nimport { input, state } from \"./base\";\n\n// ## Parser utilities\n\n// Tests whether parsed token is a contextual keyword.\nexport function isContextual(contextualKeyword) {\n  return state.contextualKeyword === contextualKeyword;\n}\nexport function isLookaheadContextual(contextualKeyword) {\n  const l = lookaheadTypeAndKeyword();\n  return l.type === tt.name && l.contextualKeyword === contextualKeyword;\n}\n\n// Consumes contextual keyword if possible.\nexport function eatContextual(contextualKeyword) {\n  return state.contextualKeyword === contextualKeyword && eat(tt.name);\n}\n\n// Asserts that following token is given contextual keyword.\nexport function expectContextual(contextualKeyword) {\n  if (!eatContextual(contextualKeyword)) {\n    unexpected();\n  }\n}\n\n// Test whether a semicolon can be inserted at the current position.\nexport function canInsertSemicolon() {\n  return match(tt.eof) || match(tt.braceR) || hasPrecedingLineBreak();\n}\nexport function hasPrecedingLineBreak() {\n  const prevToken = state.tokens[state.tokens.length - 1];\n  const lastTokEnd = prevToken ? prevToken.end : 0;\n  for (let i = lastTokEnd; i < state.start; i++) {\n    const code = input.charCodeAt(i);\n    if (code === charCodes.lineFeed || code === charCodes.carriageReturn || code === 0x2028 || code === 0x2029) {\n      return true;\n    }\n  }\n  return false;\n}\nexport function hasFollowingLineBreak() {\n  const nextStart = nextTokenStart();\n  for (let i = state.end; i < nextStart; i++) {\n    const code = input.charCodeAt(i);\n    if (code === charCodes.lineFeed || code === charCodes.carriageReturn || code === 0x2028 || code === 0x2029) {\n      return true;\n    }\n  }\n  return false;\n}\nexport function isLineTerminator() {\n  return eat(tt.semi) || canInsertSemicolon();\n}\n\n// Consume a semicolon, or, failing that, see if we are allowed to\n// pretend that there is a semicolon at this position.\nexport function semicolon() {\n  if (!isLineTerminator()) {\n    unexpected('Unexpected token, expected \";\"');\n  }\n}\n\n// Expect a token of a given type. If found, consume it, otherwise,\n// raise an unexpected token error at given pos.\nexport function expect(type) {\n  const matched = eat(type);\n  if (!matched) {\n    unexpected(`Unexpected token, expected \"${formatTokenType(type)}\"`);\n  }\n}\n\n/**\n * Transition the parser to an error state. All code needs to be written to naturally unwind in this\n * state, which allows us to backtrack without exceptions and without error plumbing everywhere.\n */\nexport function unexpected(message = \"Unexpected token\", pos = state.start) {\n  if (state.error) {\n    return;\n  }\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  const err = new SyntaxError(message);\n  err.pos = pos;\n  state.error = err;\n  state.pos = input.length;\n  finishToken(tt.eof);\n}","map":{"version":3,"names":["eat","finishToken","lookaheadTypeAndKeyword","match","nextTokenStart","formatTokenType","TokenType","tt","charCodes","input","state","isContextual","contextualKeyword","isLookaheadContextual","l","type","name","eatContextual","expectContextual","unexpected","canInsertSemicolon","eof","braceR","hasPrecedingLineBreak","prevToken","tokens","length","lastTokEnd","end","i","start","code","charCodeAt","lineFeed","carriageReturn","hasFollowingLineBreak","nextStart","isLineTerminator","semi","semicolon","expect","matched","message","pos","error","err","SyntaxError"],"sources":["D:/WEB-PROJECT/Schwarz/frontend/node_modules/sucrase/dist/esm/parser/traverser/util.js"],"sourcesContent":["import {eat, finishToken, lookaheadTypeAndKeyword, match, nextTokenStart} from \"../tokenizer/index\";\n\nimport {formatTokenType, TokenType as tt} from \"../tokenizer/types\";\nimport {charCodes} from \"../util/charcodes\";\nimport {input, state} from \"./base\";\n\n// ## Parser utilities\n\n// Tests whether parsed token is a contextual keyword.\nexport function isContextual(contextualKeyword) {\n  return state.contextualKeyword === contextualKeyword;\n}\n\nexport function isLookaheadContextual(contextualKeyword) {\n  const l = lookaheadTypeAndKeyword();\n  return l.type === tt.name && l.contextualKeyword === contextualKeyword;\n}\n\n// Consumes contextual keyword if possible.\nexport function eatContextual(contextualKeyword) {\n  return state.contextualKeyword === contextualKeyword && eat(tt.name);\n}\n\n// Asserts that following token is given contextual keyword.\nexport function expectContextual(contextualKeyword) {\n  if (!eatContextual(contextualKeyword)) {\n    unexpected();\n  }\n}\n\n// Test whether a semicolon can be inserted at the current position.\nexport function canInsertSemicolon() {\n  return match(tt.eof) || match(tt.braceR) || hasPrecedingLineBreak();\n}\n\nexport function hasPrecedingLineBreak() {\n  const prevToken = state.tokens[state.tokens.length - 1];\n  const lastTokEnd = prevToken ? prevToken.end : 0;\n  for (let i = lastTokEnd; i < state.start; i++) {\n    const code = input.charCodeAt(i);\n    if (\n      code === charCodes.lineFeed ||\n      code === charCodes.carriageReturn ||\n      code === 0x2028 ||\n      code === 0x2029\n    ) {\n      return true;\n    }\n  }\n  return false;\n}\n\nexport function hasFollowingLineBreak() {\n  const nextStart = nextTokenStart();\n  for (let i = state.end; i < nextStart; i++) {\n    const code = input.charCodeAt(i);\n    if (\n      code === charCodes.lineFeed ||\n      code === charCodes.carriageReturn ||\n      code === 0x2028 ||\n      code === 0x2029\n    ) {\n      return true;\n    }\n  }\n  return false;\n}\n\nexport function isLineTerminator() {\n  return eat(tt.semi) || canInsertSemicolon();\n}\n\n// Consume a semicolon, or, failing that, see if we are allowed to\n// pretend that there is a semicolon at this position.\nexport function semicolon() {\n  if (!isLineTerminator()) {\n    unexpected('Unexpected token, expected \";\"');\n  }\n}\n\n// Expect a token of a given type. If found, consume it, otherwise,\n// raise an unexpected token error at given pos.\nexport function expect(type) {\n  const matched = eat(type);\n  if (!matched) {\n    unexpected(`Unexpected token, expected \"${formatTokenType(type)}\"`);\n  }\n}\n\n/**\n * Transition the parser to an error state. All code needs to be written to naturally unwind in this\n * state, which allows us to backtrack without exceptions and without error plumbing everywhere.\n */\nexport function unexpected(message = \"Unexpected token\", pos = state.start) {\n  if (state.error) {\n    return;\n  }\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  const err = new SyntaxError(message);\n  err.pos = pos;\n  state.error = err;\n  state.pos = input.length;\n  finishToken(tt.eof);\n}\n"],"mappings":"AAAA,SAAQA,GAAG,EAAEC,WAAW,EAAEC,uBAAuB,EAAEC,KAAK,EAAEC,cAAc,QAAO,oBAAoB;AAEnG,SAAQC,eAAe,EAAEC,SAAS,IAAIC,EAAE,QAAO,oBAAoB;AACnE,SAAQC,SAAS,QAAO,mBAAmB;AAC3C,SAAQC,KAAK,EAAEC,KAAK,QAAO,QAAQ;;AAEnC;;AAEA;AACA,OAAO,SAASC,YAAYA,CAACC,iBAAiB,EAAE;EAC9C,OAAOF,KAAK,CAACE,iBAAiB,KAAKA,iBAAiB;AACtD;AAEA,OAAO,SAASC,qBAAqBA,CAACD,iBAAiB,EAAE;EACvD,MAAME,CAAC,GAAGZ,uBAAuB,CAAC,CAAC;EACnC,OAAOY,CAAC,CAACC,IAAI,KAAKR,EAAE,CAACS,IAAI,IAAIF,CAAC,CAACF,iBAAiB,KAAKA,iBAAiB;AACxE;;AAEA;AACA,OAAO,SAASK,aAAaA,CAACL,iBAAiB,EAAE;EAC/C,OAAOF,KAAK,CAACE,iBAAiB,KAAKA,iBAAiB,IAAIZ,GAAG,CAACO,EAAE,CAACS,IAAI,CAAC;AACtE;;AAEA;AACA,OAAO,SAASE,gBAAgBA,CAACN,iBAAiB,EAAE;EAClD,IAAI,CAACK,aAAa,CAACL,iBAAiB,CAAC,EAAE;IACrCO,UAAU,CAAC,CAAC;EACd;AACF;;AAEA;AACA,OAAO,SAASC,kBAAkBA,CAAA,EAAG;EACnC,OAAOjB,KAAK,CAACI,EAAE,CAACc,GAAG,CAAC,IAAIlB,KAAK,CAACI,EAAE,CAACe,MAAM,CAAC,IAAIC,qBAAqB,CAAC,CAAC;AACrE;AAEA,OAAO,SAASA,qBAAqBA,CAAA,EAAG;EACtC,MAAMC,SAAS,GAAGd,KAAK,CAACe,MAAM,CAACf,KAAK,CAACe,MAAM,CAACC,MAAM,GAAG,CAAC,CAAC;EACvD,MAAMC,UAAU,GAAGH,SAAS,GAAGA,SAAS,CAACI,GAAG,GAAG,CAAC;EAChD,KAAK,IAAIC,CAAC,GAAGF,UAAU,EAAEE,CAAC,GAAGnB,KAAK,CAACoB,KAAK,EAAED,CAAC,EAAE,EAAE;IAC7C,MAAME,IAAI,GAAGtB,KAAK,CAACuB,UAAU,CAACH,CAAC,CAAC;IAChC,IACEE,IAAI,KAAKvB,SAAS,CAACyB,QAAQ,IAC3BF,IAAI,KAAKvB,SAAS,CAAC0B,cAAc,IACjCH,IAAI,KAAK,MAAM,IACfA,IAAI,KAAK,MAAM,EACf;MACA,OAAO,IAAI;IACb;EACF;EACA,OAAO,KAAK;AACd;AAEA,OAAO,SAASI,qBAAqBA,CAAA,EAAG;EACtC,MAAMC,SAAS,GAAGhC,cAAc,CAAC,CAAC;EAClC,KAAK,IAAIyB,CAAC,GAAGnB,KAAK,CAACkB,GAAG,EAAEC,CAAC,GAAGO,SAAS,EAAEP,CAAC,EAAE,EAAE;IAC1C,MAAME,IAAI,GAAGtB,KAAK,CAACuB,UAAU,CAACH,CAAC,CAAC;IAChC,IACEE,IAAI,KAAKvB,SAAS,CAACyB,QAAQ,IAC3BF,IAAI,KAAKvB,SAAS,CAAC0B,cAAc,IACjCH,IAAI,KAAK,MAAM,IACfA,IAAI,KAAK,MAAM,EACf;MACA,OAAO,IAAI;IACb;EACF;EACA,OAAO,KAAK;AACd;AAEA,OAAO,SAASM,gBAAgBA,CAAA,EAAG;EACjC,OAAOrC,GAAG,CAACO,EAAE,CAAC+B,IAAI,CAAC,IAAIlB,kBAAkB,CAAC,CAAC;AAC7C;;AAEA;AACA;AACA,OAAO,SAASmB,SAASA,CAAA,EAAG;EAC1B,IAAI,CAACF,gBAAgB,CAAC,CAAC,EAAE;IACvBlB,UAAU,CAAC,gCAAgC,CAAC;EAC9C;AACF;;AAEA;AACA;AACA,OAAO,SAASqB,MAAMA,CAACzB,IAAI,EAAE;EAC3B,MAAM0B,OAAO,GAAGzC,GAAG,CAACe,IAAI,CAAC;EACzB,IAAI,CAAC0B,OAAO,EAAE;IACZtB,UAAU,CAAE,+BAA8Bd,eAAe,CAACU,IAAI,CAAE,GAAE,CAAC;EACrE;AACF;;AAEA;AACA;AACA;AACA;AACA,OAAO,SAASI,UAAUA,CAACuB,OAAO,GAAG,kBAAkB,EAAEC,GAAG,GAAGjC,KAAK,CAACoB,KAAK,EAAE;EAC1E,IAAIpB,KAAK,CAACkC,KAAK,EAAE;IACf;EACF;EACA;EACA,MAAMC,GAAG,GAAG,IAAIC,WAAW,CAACJ,OAAO,CAAC;EACpCG,GAAG,CAACF,GAAG,GAAGA,GAAG;EACbjC,KAAK,CAACkC,KAAK,GAAGC,GAAG;EACjBnC,KAAK,CAACiC,GAAG,GAAGlC,KAAK,CAACiB,MAAM;EACxBzB,WAAW,CAACM,EAAE,CAACc,GAAG,CAAC;AACrB"},"metadata":{},"sourceType":"module","externalDependencies":[]}