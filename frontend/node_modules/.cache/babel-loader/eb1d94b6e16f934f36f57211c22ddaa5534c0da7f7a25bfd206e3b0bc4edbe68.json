{"ast":null,"code":"import { GenMapping, maybeAddSegment, toEncodedMap } from \"@jridgewell/gen-mapping\";\nimport { charCodes } from \"./parser/util/charcodes\";\n\n/**\n * Generate a source map indicating that each line maps directly to the original line,\n * with the tokens in their new positions.\n */\nexport default function computeSourceMap({\n  code: generatedCode,\n  mappings: rawMappings\n}, filePath, options, source, tokens) {\n  const sourceColumns = computeSourceColumns(source, tokens);\n  const map = new GenMapping({\n    file: options.compiledFilename\n  });\n  let tokenIndex = 0;\n  // currentMapping is the output source index for the current input token being\n  // considered.\n  let currentMapping = rawMappings[0];\n  while (currentMapping === undefined && tokenIndex < rawMappings.length - 1) {\n    tokenIndex++;\n    currentMapping = rawMappings[tokenIndex];\n  }\n  let line = 0;\n  let lineStart = 0;\n  if (currentMapping !== lineStart) {\n    maybeAddSegment(map, line, 0, filePath, line, 0);\n  }\n  for (let i = 0; i < generatedCode.length; i++) {\n    if (i === currentMapping) {\n      const genColumn = currentMapping - lineStart;\n      const sourceColumn = sourceColumns[tokenIndex];\n      maybeAddSegment(map, line, genColumn, filePath, line, sourceColumn);\n      while ((currentMapping === i || currentMapping === undefined) && tokenIndex < rawMappings.length - 1) {\n        tokenIndex++;\n        currentMapping = rawMappings[tokenIndex];\n      }\n    }\n    if (generatedCode.charCodeAt(i) === charCodes.lineFeed) {\n      line++;\n      lineStart = i + 1;\n      if (currentMapping !== lineStart) {\n        maybeAddSegment(map, line, 0, filePath, line, 0);\n      }\n    }\n  }\n  const {\n    sourceRoot,\n    sourcesContent,\n    ...sourceMap\n  } = toEncodedMap(map);\n  return sourceMap;\n}\n\n/**\n * Create an array mapping each token index to the 0-based column of the start\n * position of the token.\n */\nfunction computeSourceColumns(code, tokens) {\n  const sourceColumns = new Array(tokens.length);\n  let tokenIndex = 0;\n  let currentMapping = tokens[tokenIndex].start;\n  let lineStart = 0;\n  for (let i = 0; i < code.length; i++) {\n    if (i === currentMapping) {\n      sourceColumns[tokenIndex] = currentMapping - lineStart;\n      tokenIndex++;\n      currentMapping = tokens[tokenIndex].start;\n    }\n    if (code.charCodeAt(i) === charCodes.lineFeed) {\n      lineStart = i + 1;\n    }\n  }\n  return sourceColumns;\n}","map":{"version":3,"names":["GenMapping","maybeAddSegment","toEncodedMap","charCodes","computeSourceMap","code","generatedCode","mappings","rawMappings","filePath","options","source","tokens","sourceColumns","computeSourceColumns","map","file","compiledFilename","tokenIndex","currentMapping","undefined","length","line","lineStart","i","genColumn","sourceColumn","charCodeAt","lineFeed","sourceRoot","sourcesContent","sourceMap","Array","start"],"sources":["D:/WEB-PROJECT/Schwarz/frontend/node_modules/sucrase/dist/esm/computeSourceMap.js"],"sourcesContent":["import {GenMapping, maybeAddSegment, toEncodedMap} from \"@jridgewell/gen-mapping\";\n\n\n\nimport {charCodes} from \"./parser/util/charcodes\";\n\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Generate a source map indicating that each line maps directly to the original line,\n * with the tokens in their new positions.\n */\nexport default function computeSourceMap(\n  {code: generatedCode, mappings: rawMappings},\n  filePath,\n  options,\n  source,\n  tokens,\n) {\n  const sourceColumns = computeSourceColumns(source, tokens);\n  const map = new GenMapping({file: options.compiledFilename});\n  let tokenIndex = 0;\n  // currentMapping is the output source index for the current input token being\n  // considered.\n  let currentMapping = rawMappings[0];\n  while (currentMapping === undefined && tokenIndex < rawMappings.length - 1) {\n    tokenIndex++;\n    currentMapping = rawMappings[tokenIndex];\n  }\n  let line = 0;\n  let lineStart = 0;\n  if (currentMapping !== lineStart) {\n    maybeAddSegment(map, line, 0, filePath, line, 0);\n  }\n  for (let i = 0; i < generatedCode.length; i++) {\n    if (i === currentMapping) {\n      const genColumn = currentMapping - lineStart;\n      const sourceColumn = sourceColumns[tokenIndex];\n      maybeAddSegment(map, line, genColumn, filePath, line, sourceColumn);\n      while (\n        (currentMapping === i || currentMapping === undefined) &&\n        tokenIndex < rawMappings.length - 1\n      ) {\n        tokenIndex++;\n        currentMapping = rawMappings[tokenIndex];\n      }\n    }\n    if (generatedCode.charCodeAt(i) === charCodes.lineFeed) {\n      line++;\n      lineStart = i + 1;\n      if (currentMapping !== lineStart) {\n        maybeAddSegment(map, line, 0, filePath, line, 0);\n      }\n    }\n  }\n  const {sourceRoot, sourcesContent, ...sourceMap} = toEncodedMap(map);\n  return sourceMap ;\n}\n\n/**\n * Create an array mapping each token index to the 0-based column of the start\n * position of the token.\n */\nfunction computeSourceColumns(code, tokens) {\n  const sourceColumns = new Array(tokens.length);\n  let tokenIndex = 0;\n  let currentMapping = tokens[tokenIndex].start;\n  let lineStart = 0;\n  for (let i = 0; i < code.length; i++) {\n    if (i === currentMapping) {\n      sourceColumns[tokenIndex] = currentMapping - lineStart;\n      tokenIndex++;\n      currentMapping = tokens[tokenIndex].start;\n    }\n    if (code.charCodeAt(i) === charCodes.lineFeed) {\n      lineStart = i + 1;\n    }\n  }\n  return sourceColumns;\n}\n"],"mappings":"AAAA,SAAQA,UAAU,EAAEC,eAAe,EAAEC,YAAY,QAAO,yBAAyB;AAIjF,SAAQC,SAAS,QAAO,yBAAyB;;AAajD;AACA;AACA;AACA;AACA,eAAe,SAASC,gBAAgBA,CACtC;EAACC,IAAI,EAAEC,aAAa;EAAEC,QAAQ,EAAEC;AAAW,CAAC,EAC5CC,QAAQ,EACRC,OAAO,EACPC,MAAM,EACNC,MAAM,EACN;EACA,MAAMC,aAAa,GAAGC,oBAAoB,CAACH,MAAM,EAAEC,MAAM,CAAC;EAC1D,MAAMG,GAAG,GAAG,IAAIf,UAAU,CAAC;IAACgB,IAAI,EAAEN,OAAO,CAACO;EAAgB,CAAC,CAAC;EAC5D,IAAIC,UAAU,GAAG,CAAC;EAClB;EACA;EACA,IAAIC,cAAc,GAAGX,WAAW,CAAC,CAAC,CAAC;EACnC,OAAOW,cAAc,KAAKC,SAAS,IAAIF,UAAU,GAAGV,WAAW,CAACa,MAAM,GAAG,CAAC,EAAE;IAC1EH,UAAU,EAAE;IACZC,cAAc,GAAGX,WAAW,CAACU,UAAU,CAAC;EAC1C;EACA,IAAII,IAAI,GAAG,CAAC;EACZ,IAAIC,SAAS,GAAG,CAAC;EACjB,IAAIJ,cAAc,KAAKI,SAAS,EAAE;IAChCtB,eAAe,CAACc,GAAG,EAAEO,IAAI,EAAE,CAAC,EAAEb,QAAQ,EAAEa,IAAI,EAAE,CAAC,CAAC;EAClD;EACA,KAAK,IAAIE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGlB,aAAa,CAACe,MAAM,EAAEG,CAAC,EAAE,EAAE;IAC7C,IAAIA,CAAC,KAAKL,cAAc,EAAE;MACxB,MAAMM,SAAS,GAAGN,cAAc,GAAGI,SAAS;MAC5C,MAAMG,YAAY,GAAGb,aAAa,CAACK,UAAU,CAAC;MAC9CjB,eAAe,CAACc,GAAG,EAAEO,IAAI,EAAEG,SAAS,EAAEhB,QAAQ,EAAEa,IAAI,EAAEI,YAAY,CAAC;MACnE,OACE,CAACP,cAAc,KAAKK,CAAC,IAAIL,cAAc,KAAKC,SAAS,KACrDF,UAAU,GAAGV,WAAW,CAACa,MAAM,GAAG,CAAC,EACnC;QACAH,UAAU,EAAE;QACZC,cAAc,GAAGX,WAAW,CAACU,UAAU,CAAC;MAC1C;IACF;IACA,IAAIZ,aAAa,CAACqB,UAAU,CAACH,CAAC,CAAC,KAAKrB,SAAS,CAACyB,QAAQ,EAAE;MACtDN,IAAI,EAAE;MACNC,SAAS,GAAGC,CAAC,GAAG,CAAC;MACjB,IAAIL,cAAc,KAAKI,SAAS,EAAE;QAChCtB,eAAe,CAACc,GAAG,EAAEO,IAAI,EAAE,CAAC,EAAEb,QAAQ,EAAEa,IAAI,EAAE,CAAC,CAAC;MAClD;IACF;EACF;EACA,MAAM;IAACO,UAAU;IAAEC,cAAc;IAAE,GAAGC;EAAS,CAAC,GAAG7B,YAAY,CAACa,GAAG,CAAC;EACpE,OAAOgB,SAAS;AAClB;;AAEA;AACA;AACA;AACA;AACA,SAASjB,oBAAoBA,CAACT,IAAI,EAAEO,MAAM,EAAE;EAC1C,MAAMC,aAAa,GAAG,IAAImB,KAAK,CAACpB,MAAM,CAACS,MAAM,CAAC;EAC9C,IAAIH,UAAU,GAAG,CAAC;EAClB,IAAIC,cAAc,GAAGP,MAAM,CAACM,UAAU,CAAC,CAACe,KAAK;EAC7C,IAAIV,SAAS,GAAG,CAAC;EACjB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGnB,IAAI,CAACgB,MAAM,EAAEG,CAAC,EAAE,EAAE;IACpC,IAAIA,CAAC,KAAKL,cAAc,EAAE;MACxBN,aAAa,CAACK,UAAU,CAAC,GAAGC,cAAc,GAAGI,SAAS;MACtDL,UAAU,EAAE;MACZC,cAAc,GAAGP,MAAM,CAACM,UAAU,CAAC,CAACe,KAAK;IAC3C;IACA,IAAI5B,IAAI,CAACsB,UAAU,CAACH,CAAC,CAAC,KAAKrB,SAAS,CAACyB,QAAQ,EAAE;MAC7CL,SAAS,GAAGC,CAAC,GAAG,CAAC;IACnB;EACF;EACA,OAAOX,aAAa;AACtB"},"metadata":{},"sourceType":"module","externalDependencies":[]}